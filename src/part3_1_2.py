# -*- coding: utf-8 -*-
"""Part3_1_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10k_3vJ86ia5QouEs8uF3X_k276JhSZmz
"""

pip install pyspark

import pyspark
from pyspark.sql import SparkSession
from pyspark.sql import Row




spark = SparkSession.builder.appName("answers").getOrCreate()
sparkContext=spark.sparkContext
!wget --continue  https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data -o /tmp/iris.csv
path = "/tmp/iris.csv"

"""##Task 1"""

from google.colab import drive
drive.mount('/content/drive')

from pyspark import SparkContext
from pyspark import SparkConf
from pyspark import SQLContext
columns = ["sepal_length", "sepal_width", "petal_length", "petal_width", "class"]
#iris_df = spark.read.csv('/content/iris.data')
iris_df = spark.read.csv('/content/iris.data',header=False)
iris_col_df = iris_df.withColumnRenamed('_c0',columns[0])
iris_col_df = iris_col_df.withColumnRenamed('_c1',columns[1])

iris_col_df = iris_col_df.withColumnRenamed('_c2',columns[2])

iris_col_df = iris_col_df.withColumnRenamed('_c3',columns[3])

iris_col_df = iris_col_df.withColumnRenamed('_c4',columns[4])

#iris_df=spark.read.format("csv").option("header","true").load('/content/iris.data')
iris_col_df.show()

#casting each column to double 
from pyspark.sql.types import *
iris_col_df  = iris_col_df.withColumn("sepal_length", iris_col_df["sepal_length"].cast('double'))
iris_col_df  = iris_col_df.withColumn("sepal_width", iris_col_df["sepal_width"].cast('double'))
iris_col_df  = iris_col_df.withColumn("petal_length", iris_col_df["petal_length"].cast('double'))
iris_col_df  = iris_col_df.withColumn("petal_width", iris_col_df["petal_width"].cast('double'))
#iris_col_df  = iris_col_df.withColumn("class", iris_col_df["class"].cast(''))
iris_col_data = iris_col_df.collect()

#Exchanging class column for a integer in order to be able to do predictions
from pyspark.sql.functions import regexp_replace
iris_col_df = iris_col_df.withColumn('class', regexp_replace('class', 'Iris-setosa', '1'))
iris_col_df =iris_col_df.withColumn('class', regexp_replace('class', 'Iris-versicolor', '2'))
iris_col_df =iris_col_df.withColumn('class', regexp_replace('class', 'Iris-virginica', '3'))
iris_col_df  = iris_col_df.withColumn("class", iris_col_df["class"].cast('integer'))
iris_col_df.show()

from pyspark.ml.feature import VectorAssembler
assembler = VectorAssembler(inputCols = ["sepal_length", "sepal_width", "petal_length", "petal_width"], outputCol='features')
output = assembler.transform(iris_col_df)
#df_assembler = VectorAssembler(inputCols=['sepal_length','sepal_width','petal_length', 'petal_width', 'class'], outputCol="features")
#df = df_assembler.transform(iris_df)
finalised_data = output.select("features", "class")
#type(finalised_data)

#splitting data between training and test set
training_df,test_df=finalised_data.randomSplit([0.75,0.25])
training_df.show()

from pyspark.ml.classification import LogisticRegression
# Fit Logistic Regression classifier.
logreg = LogisticRegression(labelCol='class').fit(training_df)

predictions = logreg.transform(test_df)
predictions.show()

"""##Task 2

Testing my model against pred_data
"""

pred_data = spark.createDataFrame(
 [(5.1, 3.5, 1.4, 0.2),
 (6.2, 3.4, 5.4, 2.3)],
 ["sepal_length", "sepal_width", "petal_length", "petal_width"])
output = assembler.transform(pred_data)
prediction = logreg.transform(output)
type(prediction)

prediction.select("prediction").show()

from pyspark.sql.types import StringType,BooleanType,DateType
from pyspark.sql.types import *
from pyspark.sql.functions import col
prediction_df = prediction.withColumn('prediction', regexp_replace('prediction', '1', 'Irish-sentosa'))
prediction_df = prediction_df.withColumn('prediction', regexp_replace('prediction', '2', 'Irish-veriscolor'))
prediction_df = prediction_df.withColumn('prediction', regexp_replace('prediction', '3', 'Irish-virginica'))
#prediction_df_cast  = prediction_df.withColumn('prediction', prediction_df.prediction.cast(StringType()))
prediction_df_cast = prediction_df.withColumn('prediction', col('prediction').cast('string'))
prediction_df_cast.show()

prediction_class_df = prediction_df_cast.select("prediction")

prediction_class_df.write.option("header",True) \
 .csv("/content/drive/MyDrive/out3_2.txt")

